{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moledetection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries needed for this notebook\n",
    "###############################################\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import autokeras as ak\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Classes to predict\n",
    "seven={\n",
    "                'nv':'Melanocytic nevi',\n",
    "                'mel':'Melanoma',\n",
    "                'bkl':'Benign keratosis-like lesions',\n",
    "                'bcc':'Basal cell carcinoma',\n",
    "                'akiec':'Actinic keratoses',\n",
    "                'vas':'Vascular lesions',\n",
    "                'df':'Dermatofibroma'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part should only be run once !\n",
    "#\n",
    "# Prepare directory structure for augmented images to balance the dataset\n",
    "#########################################################################################\n",
    "#   \n",
    "# dataset is unbalanced\n",
    "#            6705 images for   'nv':'Melanocytic nevi',\n",
    "#            1113 images for   'mel':'Melanoma',\n",
    "#            1099 images for   'bkl':'Benign keratosis-like lesions',\n",
    "#            514  images for  'bcc':'Basal cell carcinoma',\n",
    "#            327  images for  'akiec':'Actinic keratoses',\n",
    "#            142  images for  'vas':'Vascular lesions',\n",
    "#            115  images for  'df':'Dermatofibroma'\n",
    "#      \n",
    "# create directory structure :\n",
    "##############################\n",
    "# ./backup/data/HAM10000/HAM10000_images_part_1  <-- contains the downloaded first imageset\n",
    "# ./backup/data/HAM10000/HAM10000_images_part_2  <-- contains the downloaded second imageset\n",
    "# ./backup/data/HAM10000/HAM10000_metadata.csv    <-- contains the downloaded csv with picnames with prediction\n",
    "#\n",
    "# ./backup/data/HAM10000/ALL          <-- create directory and put all available images here \n",
    "#\n",
    "# create directories for every class as follows\n",
    "###############################################\n",
    "#\n",
    "# ./backup/data/HAM10000/myaugmenting/nv\n",
    "# ./backup/data/HAM10000/myaugmenting/mel\n",
    "# ./backup/data/HAM10000/myaugmenting/bkl\n",
    "# ./backup/data/HAM10000/myaugmenting/bcc\n",
    "# ./backup/data/HAM10000/myaugmenting/akiec\n",
    "# ./backup/data/HAM10000/myaugmenting/vas\n",
    "# ./backup/data/HAM10000/myaugmenting/df\n",
    "#\n",
    "# ./backup/data/HAM10000/myaugmenting/nv_out\n",
    "# ./backup/data/HAM10000/myaugmenting/mel_out\n",
    "# ./backup/data/HAM10000/myaugmenting/bkl_out\n",
    "# ./backup/data/HAM10000/myaugmenting/bcc_out\n",
    "# ./backup/data/HAM10000/myaugmenting/akiec_out\n",
    "# ./backup/data/HAM10000/myaugmenting/vas_out\n",
    "# ./backup/data/HAM10000/myaugmenting/df_out\n",
    "#\n",
    "###############################################\n",
    "\n",
    "# copy the images from 'ALL' directory to the corresponding class subdirectories in directory 'myaugmenting'\n",
    "############################################################################################################\n",
    "df=pd.read_csv(\"./backup/data/HAM10000/HAM10000_metadata.csv\")\n",
    "df['frm']='./backup/data/HAM10000/ALL/'+df['image_id']+'.jpg'\n",
    "df['to']='./backup/data/HAM10000/myaugmenting/'+df['dx']+'/'+df['image_id']+'.jpg'\n",
    "df=df[['frm','to']]\n",
    "fromtolist=df.values.tolist()\n",
    "i=0\n",
    "j=0\n",
    "for frm,to in fromtolist:\n",
    "    try:\n",
    "        shutil.copyfile(frm, to)\n",
    "    except:\n",
    "        j+=1\n",
    "    i+=1\n",
    "    print (f\"\\r>> copied: {i}    could not copy: {j}\", end='', flush=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nv\n",
      "Found 6401 images belonging to 1 classes.\n",
      ">> img created: 1<class 'tuple'>\n",
      ">> img created: 2<class 'tuple'>\n",
      "mel\n",
      "Found 1014 images belonging to 1 classes.\n",
      ">> img created: 1<class 'tuple'>\n",
      ">> img created: 2<class 'tuple'>\n",
      ">> img created: 3<class 'tuple'>\n",
      ">> img created: 4<class 'tuple'>\n",
      ">> img created: 5<class 'tuple'>\n",
      ">> img created: 6<class 'tuple'>\n",
      ">> img created: 7<class 'tuple'>\n",
      "bkl\n",
      "Found 1000 images belonging to 1 classes.\n",
      ">> img created: 1<class 'tuple'>\n",
      ">> img created: 2<class 'tuple'>\n",
      ">> img created: 3<class 'tuple'>\n",
      ">> img created: 4<class 'tuple'>\n",
      ">> img created: 5<class 'tuple'>\n",
      ">> img created: 6<class 'tuple'>\n",
      ">> img created: 7<class 'tuple'>\n",
      "bcc\n",
      "Found 459 images belonging to 1 classes.\n",
      ">> img created: 1<class 'tuple'>\n",
      ">> img created: 2<class 'tuple'>\n",
      ">> img created: 3<class 'tuple'>\n",
      ">> img created: 4<class 'tuple'>\n",
      ">> img created: 5<class 'tuple'>\n",
      ">> img created: 6<class 'tuple'>\n",
      ">> img created: 7<class 'tuple'>\n",
      ">> img created: 8<class 'tuple'>\n",
      ">> img created: 9<class 'tuple'>\n",
      ">> img created: 10<class 'tuple'>\n",
      ">> img created: 11<class 'tuple'>\n",
      ">> img created: 12<class 'tuple'>\n",
      ">> img created: 13<class 'tuple'>\n",
      ">> img created: 14<class 'tuple'>\n",
      "akiec\n",
      "Found 294 images belonging to 1 classes.\n",
      ">> img created: 1<class 'tuple'>\n",
      ">> img created: 2<class 'tuple'>\n",
      ">> img created: 3<class 'tuple'>\n",
      ">> img created: 4<class 'tuple'>\n",
      ">> img created: 5<class 'tuple'>\n",
      ">> img created: 6<class 'tuple'>\n",
      ">> img created: 7<class 'tuple'>\n",
      ">> img created: 8<class 'tuple'>\n",
      ">> img created: 9<class 'tuple'>\n",
      ">> img created: 10<class 'tuple'>\n",
      ">> img created: 11<class 'tuple'>\n",
      ">> img created: 12<class 'tuple'>\n",
      ">> img created: 13<class 'tuple'>\n",
      ">> img created: 14<class 'tuple'>\n",
      ">> img created: 15<class 'tuple'>\n",
      ">> img created: 16<class 'tuple'>\n",
      ">> img created: 17<class 'tuple'>\n",
      ">> img created: 18<class 'tuple'>\n",
      ">> img created: 19<class 'tuple'>\n",
      ">> img created: 20<class 'tuple'>\n",
      ">> img created: 21<class 'tuple'>\n",
      "vas\n",
      "Found 127 images belonging to 1 classes.\n",
      ">> img created: 1<class 'tuple'>\n",
      ">> img created: 2<class 'tuple'>\n",
      ">> img created: 3<class 'tuple'>\n",
      ">> img created: 4<class 'tuple'>\n",
      ">> img created: 5<class 'tuple'>\n",
      ">> img created: 6<class 'tuple'>\n",
      ">> img created: 7<class 'tuple'>\n",
      ">> img created: 8<class 'tuple'>\n",
      ">> img created: 9<class 'tuple'>\n",
      ">> img created: 10<class 'tuple'>\n",
      ">> img created: 11<class 'tuple'>\n",
      ">> img created: 12<class 'tuple'>\n",
      ">> img created: 13<class 'tuple'>\n",
      ">> img created: 14<class 'tuple'>\n",
      ">> img created: 15<class 'tuple'>\n",
      ">> img created: 16<class 'tuple'>\n",
      ">> img created: 17<class 'tuple'>\n",
      ">> img created: 18<class 'tuple'>\n",
      ">> img created: 19<class 'tuple'>\n",
      ">> img created: 20<class 'tuple'>\n",
      ">> img created: 21<class 'tuple'>\n",
      ">> img created: 22<class 'tuple'>\n",
      ">> img created: 23<class 'tuple'>\n",
      ">> img created: 24<class 'tuple'>\n",
      ">> img created: 25<class 'tuple'>\n",
      ">> img created: 26<class 'tuple'>\n",
      ">> img created: 27<class 'tuple'>\n",
      ">> img created: 28<class 'tuple'>\n",
      ">> img created: 29<class 'tuple'>\n",
      ">> img created: 30<class 'tuple'>\n",
      ">> img created: 31<class 'tuple'>\n",
      ">> img created: 32<class 'tuple'>\n",
      ">> img created: 33<class 'tuple'>\n",
      ">> img created: 34<class 'tuple'>\n",
      ">> img created: 35<class 'tuple'>\n",
      ">> img created: 36<class 'tuple'>\n",
      ">> img created: 37<class 'tuple'>\n",
      ">> img created: 38<class 'tuple'>\n",
      ">> img created: 39<class 'tuple'>\n",
      ">> img created: 40<class 'tuple'>\n",
      ">> img created: 41<class 'tuple'>\n",
      ">> img created: 42<class 'tuple'>\n",
      ">> img created: 43<class 'tuple'>\n",
      ">> img created: 44<class 'tuple'>\n",
      ">> img created: 45<class 'tuple'>\n",
      ">> img created: 46<class 'tuple'>\n",
      ">> img created: 47<class 'tuple'>\n",
      ">> img created: 48<class 'tuple'>\n",
      "df\n",
      "Found 105 images belonging to 1 classes.\n",
      ">> img created: 1<class 'tuple'>\n",
      ">> img created: 2<class 'tuple'>\n",
      ">> img created: 3<class 'tuple'>\n",
      ">> img created: 4<class 'tuple'>\n",
      ">> img created: 5<class 'tuple'>\n",
      ">> img created: 6<class 'tuple'>\n",
      ">> img created: 7<class 'tuple'>\n",
      ">> img created: 8<class 'tuple'>\n",
      ">> img created: 9<class 'tuple'>\n",
      ">> img created: 10<class 'tuple'>\n",
      ">> img created: 11<class 'tuple'>\n",
      ">> img created: 12<class 'tuple'>\n",
      ">> img created: 13<class 'tuple'>\n",
      ">> img created: 14<class 'tuple'>\n",
      ">> img created: 15<class 'tuple'>\n",
      ">> img created: 16<class 'tuple'>\n",
      ">> img created: 17<class 'tuple'>\n",
      ">> img created: 18<class 'tuple'>\n",
      ">> img created: 19<class 'tuple'>\n",
      ">> img created: 20<class 'tuple'>\n",
      ">> img created: 21<class 'tuple'>\n",
      ">> img created: 22<class 'tuple'>\n",
      ">> img created: 23<class 'tuple'>\n",
      ">> img created: 24<class 'tuple'>\n",
      ">> img created: 25<class 'tuple'>\n",
      ">> img created: 26<class 'tuple'>\n",
      ">> img created: 27<class 'tuple'>\n",
      ">> img created: 28<class 'tuple'>\n",
      ">> img created: 29<class 'tuple'>\n",
      ">> img created: 30<class 'tuple'>\n",
      ">> img created: 31<class 'tuple'>\n",
      ">> img created: 32<class 'tuple'>\n",
      ">> img created: 33<class 'tuple'>\n",
      ">> img created: 34<class 'tuple'>\n",
      ">> img created: 35<class 'tuple'>\n",
      ">> img created: 36<class 'tuple'>\n",
      ">> img created: 37<class 'tuple'>\n",
      ">> img created: 38<class 'tuple'>\n",
      ">> img created: 39<class 'tuple'>\n",
      ">> img created: 40<class 'tuple'>\n",
      ">> img created: 41<class 'tuple'>\n",
      ">> img created: 42<class 'tuple'>\n",
      ">> img created: 43<class 'tuple'>\n",
      ">> img created: 44<class 'tuple'>\n",
      ">> img created: 45<class 'tuple'>\n",
      ">> img created: 46<class 'tuple'>\n",
      ">> img created: 47<class 'tuple'>\n",
      ">> img created: 48<class 'tuple'>\n",
      ">> img created: 49<class 'tuple'>\n",
      ">> img created: 50<class 'tuple'>\n",
      ">> img created: 51<class 'tuple'>\n",
      ">> img created: 52<class 'tuple'>\n",
      ">> img created: 53<class 'tuple'>\n",
      ">> img created: 54<class 'tuple'>\n",
      ">> img created: 55<class 'tuple'>\n",
      ">> img created: 56<class 'tuple'>\n",
      ">> img created: 57<class 'tuple'>\n",
      ">> img created: 58<class 'tuple'>\n",
      ">> img created: 59<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create augmented images and save them in the _out subdirectories for every class\n",
    "##################################################################################\n",
    "\n",
    "imagegenerator = ImageDataGenerator(\n",
    "        rescale=1 / 255.0,\n",
    "        rotation_range=51,\n",
    "        zoom_range=0.07,\n",
    "        width_shift_range=0.07,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "        validation_split=0.20)\n",
    "\n",
    "\n",
    "# the number of available images per class in original dataset\n",
    "sevennmbr={\n",
    "            'nv':6705,\n",
    "            'mel':1113,\n",
    "            'bkl':1099,\n",
    "            'bcc':514,\n",
    "            'akiec':327,\n",
    "            'vas':142,\n",
    "            'df':115\n",
    "            }\n",
    "\n",
    "for classname in seven.keys():\n",
    "    save_directory='../backup/data/HAM10000/picaugment/' + classname + '_out'\n",
    "    directory='../backup/data/HAM10000/picaugment/' + classname + '/'\n",
    "\n",
    "    img_gen=imagegenerator.flow_from_directory(\n",
    "        directory=directory,\n",
    "        target_size=(256, 256),\n",
    "        color_mode='rgb',\n",
    "        classes=[classname],\n",
    "        class_mode='categorical',\n",
    "        batch_size=sevennmbr[classname],\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        save_to_dir=save_directory,\n",
    "        save_prefix=classname,\n",
    "        save_format='png',\n",
    "        follow_links=False,\n",
    "        subset=None,\n",
    "        interpolation='nearest',\n",
    "        keep_aspect_ratio=False\n",
    "    )\n",
    "\n",
    "# Depending on how many images we have create necessary augmented images\n",
    "# when iterating trough they will be created in the corresponding subdirectory\n",
    "    i=0\n",
    "    for img in img_gen:\n",
    "        i+=1\n",
    "        print (f\"\\r>> img created: {i}\", end='', flush=True)\n",
    "        print(type(img))\n",
    "        if i == 1 + int(6710/(sevennmbr[classname])):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['akiec' 'bcc' 'bkl' 'df' 'mel' 'nv' 'vas']\n",
      "(51791, 64, 64, 3) (51791, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create an X and Y_cat for modelling\n",
    "######################################\n",
    "#\n",
    "\n",
    "# Get the list of all imagefiles with their subdirectory\n",
    "mergeinfo=[]\n",
    "for i in ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vas']:\n",
    "    path = \"../backup/data/HAM10000/picaugment/\" + i + \"_out\"\n",
    "    dir_list = os.listdir(path)\n",
    "    stopcnt=20000\n",
    "    for j in dir_list:\n",
    "        full=path + \"/\" + j\n",
    "        mergeinfo.append([i,full])\n",
    "        stopcnt-=1\n",
    "        if stopcnt == 0:\n",
    "            break \n",
    "    \n",
    "dfinfo=pd.DataFrame(mergeinfo, columns=['dx','path'])\n",
    "\n",
    "# encode categorical\n",
    "le = LabelEncoder()\n",
    "le.fit(dfinfo['dx'])\n",
    "dfinfo['label'] = le.transform(dfinfo[\"dx\"]) \n",
    "\n",
    "#Use the path to read images.\n",
    "SIZE=64\n",
    "dfinfo['image'] = dfinfo['path'].map(lambda x: np.asarray(Image.open(x).resize((SIZE,SIZE))))\n",
    "#Convert dataframe column of images into numpy array\n",
    "X = np.asarray(dfinfo['image'].tolist())\n",
    "X = X/255. # Scale values\n",
    "Y=dfinfo['label'] # Assign labelencoded values to Y (0 to 6)\n",
    "Y_cat = to_categorical(Y, num_classes=7) #Convert to categorical ex. 2 -becomes-> [0,0,1,0,0,0,0]\n",
    "\n",
    "#print(X.shape, Y_cat.shape)\n",
    "# output : X, Y_cat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# start model selection\n",
      "INFO:tensorflow:Reloading Oracle from existing project .\\image_classifier\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\image_classifier\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/25\n",
      "81/81 [==============================] - 58s 701ms/step - loss: 1.8333 - accuracy: 0.2471\n",
      "Epoch 2/25\n",
      "81/81 [==============================] - 56s 694ms/step - loss: 1.7120 - accuracy: 0.3409\n",
      "Epoch 3/25\n",
      "81/81 [==============================] - 56s 694ms/step - loss: 1.6057 - accuracy: 0.3749\n",
      "Epoch 4/25\n",
      "81/81 [==============================] - 56s 693ms/step - loss: 1.5257 - accuracy: 0.4081\n",
      "Epoch 5/25\n",
      "81/81 [==============================] - 56s 697ms/step - loss: 1.4491 - accuracy: 0.4216\n",
      "Epoch 6/25\n",
      "81/81 [==============================] - 57s 699ms/step - loss: 1.4092 - accuracy: 0.4517\n",
      "Epoch 7/25\n",
      "81/81 [==============================] - 57s 703ms/step - loss: 1.3771 - accuracy: 0.4568\n",
      "Epoch 8/25\n",
      "81/81 [==============================] - 57s 699ms/step - loss: 1.3523 - accuracy: 0.4579\n",
      "Epoch 9/25\n",
      "81/81 [==============================] - 56s 696ms/step - loss: 1.3096 - accuracy: 0.4734\n",
      "Epoch 10/25\n",
      "81/81 [==============================] - 56s 692ms/step - loss: 1.2925 - accuracy: 0.4807\n",
      "Epoch 11/25\n",
      "81/81 [==============================] - 56s 691ms/step - loss: 1.2524 - accuracy: 0.4907\n",
      "Epoch 12/25\n",
      "81/81 [==============================] - 56s 691ms/step - loss: 1.2130 - accuracy: 0.4988\n",
      "Epoch 13/25\n",
      "81/81 [==============================] - 56s 696ms/step - loss: 1.2183 - accuracy: 0.5015\n",
      "Epoch 14/25\n",
      "81/81 [==============================] - 56s 691ms/step - loss: 1.1840 - accuracy: 0.5224\n",
      "Epoch 15/25\n",
      "81/81 [==============================] - 56s 692ms/step - loss: 1.1825 - accuracy: 0.5236\n",
      "Epoch 16/25\n",
      "81/81 [==============================] - 57s 709ms/step - loss: 1.1476 - accuracy: 0.5286\n",
      "Epoch 17/25\n",
      "81/81 [==============================] - 57s 706ms/step - loss: 1.1277 - accuracy: 0.5347\n",
      "Epoch 18/25\n",
      "81/81 [==============================] - 56s 697ms/step - loss: 1.1341 - accuracy: 0.5514\n",
      "Epoch 19/25\n",
      "81/81 [==============================] - 56s 696ms/step - loss: 1.1137 - accuracy: 0.5502\n",
      "Epoch 20/25\n",
      "81/81 [==============================] - 56s 695ms/step - loss: 1.0893 - accuracy: 0.5610\n",
      "Epoch 21/25\n",
      "81/81 [==============================] - 56s 697ms/step - loss: 1.0756 - accuracy: 0.5846\n",
      "Epoch 22/25\n",
      "81/81 [==============================] - 57s 698ms/step - loss: 1.0414 - accuracy: 0.5938\n",
      "Epoch 23/25\n",
      "81/81 [==============================] - 57s 704ms/step - loss: 1.0291 - accuracy: 0.6054\n",
      "Epoch 24/25\n",
      "81/81 [==============================] - 57s 707ms/step - loss: 0.9999 - accuracy: 0.6015\n",
      "Epoch 25/25\n",
      "81/81 [==============================] - 57s 704ms/step - loss: 0.9730 - accuracy: 0.6147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\image_classifier\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\image_classifier\\best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Evaluate the classifier on test data \n",
      "81/81 [==============================] - 14s 172ms/step - loss: 1.0991 - accuracy: 0.5842\n",
      "Accuracy =  58.4169864654541 %\n",
      "# get the final best performing model \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " cast_to_float32 (CastToFloa  (None, 64, 64, 3)        0         \n",
      " t32)                                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 64, 64, 3)        7         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 30, 30, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 512)       295424    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 13, 13, 512)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 32)        147488    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 9, 9, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 3591      \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 7)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 512,078\n",
      "Trainable params: 512,071\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n",
      "None\n",
      "#Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../pybin/models/activemodel_best_to_train\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../pybin/models/activemodel_best_to_train\\assets\n"
     ]
    }
   ],
   "source": [
    "# let autokeras select a model using the augmented dataset \n",
    "#\n",
    "# for testing/validating the best model we will use small portion 5% test 5% train\n",
    "##################################################################################\n",
    "#\n",
    "# start model selection\n",
    "#\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_cat, test_size=0.10, random_state=42, shuffle=True)\n",
    "x_train_auto, x_test_auto, y_train_auto, y_test_auto = train_test_split(X_test, Y_test, test_size=0.5, random_state=42, shuffle=True)\n",
    "#\n",
    "# start model selection\n",
    "# Define classifier for autokeras. Check 25 different models, each model 25 epochs\n",
    "# \n",
    "clf = ak.ImageClassifier(max_trials=25) #MaxTrials - max. number of keras models to try\n",
    "clf.fit(x_train_auto, y_train_auto, epochs=25)\n",
    "\n",
    "#Evaluate the classifier on test data\n",
    "\n",
    "_, acc = clf.evaluate(x_test_auto, y_test_auto)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
    "\n",
    "# get the final best performing model\n",
    "model = clf.export_model()\n",
    "\n",
    "#Save the best model \n",
    "model.save('../pybin/models/activemodel_best_to_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 735s 720ms/step - loss: 1.0972 - accuracy: 0.5768\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 741s 727ms/step - loss: 1.0217 - accuracy: 0.6075\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 733s 719ms/step - loss: 0.9623 - accuracy: 0.6305\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 735s 720ms/step - loss: 0.9192 - accuracy: 0.6500\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 734s 720ms/step - loss: 0.8827 - accuracy: 0.6612\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 741s 726ms/step - loss: 0.8514 - accuracy: 0.6736\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 733s 719ms/step - loss: 0.8338 - accuracy: 0.6783\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 734s 719ms/step - loss: 0.8150 - accuracy: 0.6853\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 723s 709ms/step - loss: 0.7946 - accuracy: 0.6969\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 721s 707ms/step - loss: 0.7839 - accuracy: 0.7024\n",
      "437/437 [==============================] - 79s 181ms/step - loss: 0.7493 - accuracy: 0.7170\n",
      "[0.7492948770523071, 0.7170337438583374]\n",
      "#Save the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../pybin/models/activemodel_best_trained\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../pybin/models/activemodel_best_trained\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../pybin/models/activemodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../pybin/models/activemodel\\assets\n"
     ]
    }
   ],
   "source": [
    "# train the best model\n",
    "######################\n",
    "#\n",
    "\n",
    "# Split the data in train/test set \n",
    "X_train_augm, X_test_augm, Y_train_augm, Y_test_augm = train_test_split(X_train, Y_train, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Load the model to train\n",
    "model = keras.models.load_model('../pybin/models/activemodel_best_to_train')\n",
    "# Train\n",
    "model.fit(X_train_augm,Y_train_augm,epochs=10)\n",
    "# Evaluate\n",
    "res=model.evaluate(X_test_augm,Y_test_augm)\n",
    "\n",
    "# Save the model\n",
    "model.save('../pybin/models/activemodel_best_trained')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 209ms/step\n",
      "[[9.4145754e-08 1.5575818e-03 1.3532737e-06 6.3111584e-05 8.4166946e-05\n",
      "  6.0101952e-03 9.9228352e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Do a testprediction\n",
    "###################\n",
    "#\n",
    "model = keras.models.load_model('../pybin/models/activemodel_best_trained')\n",
    "\n",
    "# If importing an external image you'll have to rescale it (so : divide by 225.)\n",
    "#The augmented data in X_test_augm is are already rescaled!\n",
    "img=np.reshape(X_test_augm[0], (-1, 64, 64, 3)) \n",
    "#\n",
    "y_pred=model.predict(img)\n",
    "# print result\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_augm[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad39fc4de9d0ed75de8360435f22c5c59caf607eb9db992e2697dd87e09bea1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
