{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained and transfer learning with keras\n",
    "\n",
    "Oftentimes, we are not going to reinvent the wheel, but use a **pre-trained network** to recognize entities. For some applications, there are very performant out-of-the-box solutions, and making your own model from scratch would be a waste of your valuable time.\n",
    "\n",
    "Other times, you have an application for which the out-of-the-box solutions are not exactly what you need. For this, you could use **transfer learning** to adapt a network for your use case. We will view both cases here.\n",
    "\n",
    "## 1. Pre-trained model usage\n",
    "\n",
    "In this chapter, we will learn how to import a **Keras** model that has been pre-trained to recognize various objects in full-color images.\n",
    "\n",
    "### 1.1 Importing an existing model\n",
    "\n",
    "Head on over to the official [Keras applications](https://keras.io/api/applications/) webpage to check out what models are there to pick and choose for our object recognition task.\n",
    "\n",
    "For this exercise, **you** can choose what network to pick. Look online what models are often used, or look at the evaluation metrics on the given webpage to determine which one is fit for the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import your chosen model!\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# Make a model object. Make sure you include the top as well!\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# Look at the model architecture.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preparing your images\n",
    "\n",
    "Go raid your Google photos or the World Wide Web for some pictures you want to get identified! Be sure to **pick pictures with only one clear object** inside. When you get to OpenCV model usage, you'll learn how to properly identify regions of interest in an image, but let's take one thing at a time here and keep our images simple.\n",
    "\n",
    "Keras also has a neat function to preprocess images **in the same way the training images for a network were preprocessed**. This is pretty handy to improve the model performance with those seedy pictures you found in your personal stash.\n",
    "\n",
    "Things like pixel scaling or color contrasting are applied using these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the keras preprocessing method.\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load your image. Make sure it is loaded in with the right dimensions for your model!\n",
    "image_size = (224, 224)\n",
    "original_image = image.load_img(\"./../assets/rick.jpg\", target_size=image_size)\n",
    "\n",
    "# Convert your image pixels to a numpy array of values .\n",
    "image_array = image.img_to_array(original_image)\n",
    "\n",
    "# Reshape your image dimensions so that the colour channels correspond to what your model expects.\n",
    "image_array = image_array.reshape((1, image_array.shape[0], image_array.shape[1], image_array.shape[2]))\n",
    "\n",
    "# Preprocess your image with preprocess_input.\n",
    "prepared_image = preprocess_input(image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Predicting the class of your image\n",
    "\n",
    "Let's take this bad boy for a spin! Can your image get properly identified? Finish the code down below and find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n04350905', 'suit', 0.9921138)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import decode_predictions\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Predict the class of your picture.\n",
    "prediction = model.predict(prepared_image)\n",
    "\n",
    "# Decode your prediction into a set of human readable labels.\n",
    "labels = decode_predictions(prediction)\n",
    "\n",
    "# Get the most likely result from your set of labels.\n",
    "label = labels[0][0]\n",
    "\n",
    "# Print out your result.\n",
    "print(label)\n",
    "\n",
    "# Show handsome rick.\n",
    "plt.imshow(original_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how did we do? your final result should return a general label of the object in the picture, but the performance might not be up to your expectation. Why is this? \n",
    "\n",
    "This could be due to the fact that these are general object recognition models, they are trained on **a lot** of image, but also a lot of different classes of images. What would happen if you took the best part of your pre-trained network, and adapt the output to specialize to just a few of your own chosen classes? Let's check this out in the next part...\n",
    "\n",
    "## 2. Transfer learning\n",
    "\n",
    "Many of the steps of pre-trained model learning still apply to transfer learning, but this time around, we're going to use our own dataset to help the model specialize in a particular subject.\n",
    "\n",
    "Take a look at the image below: \n",
    "![low-to-high](./../assets/low-to-high.png)\n",
    "\n",
    "It shows how a particular object is recognized at the different stages of a CNN. With our pre-trained CNN, it's no different. Instead of retraining a full neural network to extract low-level features such as lines, or other common patterns, we **keep the general feature extraction** of a pre-trained network and **replace the nonlinear association of features** done in the last few dense layers of the network.\n",
    "\n",
    "Some features may be shared by multiple classes in our use case (with animals, this is often the case), while others are only specific to a single class of the network. That's quite okay though, even if the model has been trained to extract features from classes not present in the final set of classes, this is training you don't have to redo anyway. The only difference is a small redundancy and (non-noticeable) slowdown during model prediction because of the larger model size.\n",
    "\n",
    "So in short, the advantages of transfer learning are:\n",
    "- No need to train a whole model from scratch\n",
    "- less training data required (less DOF(degrees of freedom) to fill)\n",
    "- lower level feature extraction from pre-trained networks can be reused\n",
    "- output classes can be changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importing and preprocessing the data\n",
    "\n",
    "Having a general model is all fine and dandy, but I want to **relax** the object identification problem by **reducing** the amount of classes in our model. I want a model that can accurately **identify hot dogs** from not hot dogs!\n",
    "\n",
    "Go and download the data from [this Kaggle dataset](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog), and go through the motions of preparing the data for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_preprocessed_images(images_directory: str, image_size: tuple) -> list:\n",
    "    images = []\n",
    "    for img in os.listdir(images_directory):\n",
    "        img = image.load_img(images_directory+img, target_size=image_size)\n",
    "        img = image.img_to_array(img)\n",
    "        img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "        img = preprocess_input(img)\n",
    "        images.append(img)\n",
    "    return np.vstack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_preprocessed_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load your images and preprocess them.\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m hot_dog_images \u001b[38;5;241m=\u001b[39m \u001b[43mget_preprocessed_images\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./../assets/full/hot_dog/\u001b[39m\u001b[38;5;124m\"\u001b[39m, image_size)\n\u001b[0;32m      6\u001b[0m non_hot_dog_images \u001b[38;5;241m=\u001b[39m get_preprocessed_images(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./../assets/full/not_hot_dog/\u001b[39m\u001b[38;5;124m\"\u001b[39m, image_size)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Make a numpy array for each of the class labels (one hot encoded).\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_preprocessed_images' is not defined"
     ]
    }
   ],
   "source": [
    "# Import the keras preprocessing method.\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load your images and preprocess them.\n",
    "hot_dog_images = get_preprocessed_images(\"./../assets/full/hot_dog/\", image_size)\n",
    "non_hot_dog_images = get_preprocessed_images(\"./../assets/full/not_hot_dog/\", image_size)\n",
    "\n",
    "# Make a numpy array for each of the class labels (one hot encoded).\n",
    "hot_dog_labels = np.tile([1, 0], (hot_dog_images.shape[0], 1))\n",
    "non_hot_dog_labels = np.tile([0, 1], (non_hot_dog_images.shape[0], 1))\n",
    "\n",
    "# Concatenate your images and your labels into X and y.\n",
    "X = np.concatenate([hot_dog_images, non_hot_dog_images])\n",
    "y = np.concatenate([hot_dog_labels, non_hot_dog_labels])\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always when training a model, we need to split our data in a train and a test set. For deep learning, a validation set is oftentimes used as well. Kind of foggy on the [different purposes](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7) of these sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, \n",
    "    y,\n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, \n",
    "    y_train_val,\n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Augmenting the data\n",
    "\n",
    "We don't have that many hot dogs to look at, let's squeeze as much information out of the training data by augmenting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Determine the number of generated samples you want per original sample.\n",
    "datagen_batch_size = 16\n",
    "\n",
    "# Make a datagenerator object using ImageDataGenerator.\n",
    "train_datagen = ImageDataGenerator(rotation_range=60,\n",
    "                                    horizontal_flip=True)\n",
    "\n",
    "# Feed the generator your train data.\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=datagen_batch_size)\n",
    "\n",
    "# Make a datagenerator object using ImageDataGenerator.\n",
    "validation_datagen = ImageDataGenerator(rotation_range=60,\n",
    "                                        horizontal_flip=True)\n",
    "\n",
    "# Feed the generator your validation data.\n",
    "validation_generator = validation_datagen.flow(X_val, y_val, batch_size=datagen_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Importing part of an existing model\n",
    "\n",
    "Let's import one of the application of the keras library, but make sure you don't import the final layers (the dense layers used to associate features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import your chosen model!\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "# Make a model object. \n",
    "# Make sure you exclude the top part. set the input shape of the model to 224x224 pixels, with 3 color channels.\n",
    "model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "# Freeze the imported layers so they cannot be retrained.\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Adding flattening and dense layers\n",
    "\n",
    "Right now, our model is missing a top to actually classify our features. Let's add them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 62720)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4014144   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 6,272,258\n",
      "Trainable params: 4,014,274\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "\n",
    "new_model = Sequential()\n",
    "new_model.add(model)\n",
    "new_model.add(Flatten())\n",
    "new_model.add(Dense(64, activation='relu'))\n",
    "new_model.add(Dropout(0.5))\n",
    "new_model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# Summarize.\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Training and evaluating the model\n",
    "\n",
    "All that's left to do is to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 9s 428ms/step - loss: 2.3265 - accuracy: 0.8219 - val_loss: 0.9004 - val_accuracy: 0.8125\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 9s 464ms/step - loss: 0.3906 - accuracy: 0.9031 - val_loss: 0.2944 - val_accuracy: 0.8250\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 9s 460ms/step - loss: 0.3090 - accuracy: 0.8938 - val_loss: 0.4981 - val_accuracy: 0.8625\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 9s 459ms/step - loss: 0.1936 - accuracy: 0.9250 - val_loss: 0.5408 - val_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 9s 458ms/step - loss: 0.3315 - accuracy: 0.9000 - val_loss: 0.3848 - val_accuracy: 0.8375\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 9s 459ms/step - loss: 0.3471 - accuracy: 0.9031 - val_loss: 0.4125 - val_accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 10s 477ms/step - loss: 0.2482 - accuracy: 0.9281 - val_loss: 0.4145 - val_accuracy: 0.8375\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 10s 498ms/step - loss: 0.2008 - accuracy: 0.9187 - val_loss: 0.4937 - val_accuracy: 0.9000\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 10s 492ms/step - loss: 0.2455 - accuracy: 0.9312 - val_loss: 0.3760 - val_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 9s 474ms/step - loss: 0.2157 - accuracy: 0.9281 - val_loss: 0.3767 - val_accuracy: 0.8625\n"
     ]
    }
   ],
   "source": [
    "# Compile and fit the model. Use the Adam optimizer and crossentropical loss. \n",
    "# Use the validation data argument during fitting to include your validation data.\n",
    "new_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "history = new_model.fit(train_generator,\n",
    "                        epochs=10, \n",
    "                        batch_size=8,\n",
    "                        validation_data=validation_generator\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how you did with this handy helper function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "def plot_history(history : tensorflow.python.keras.callbacks.History):\n",
    "    \"\"\" This helper function takes the tensorflow.python.keras.callbacks.History\n",
    "    that is output from your `fit` method to plot the loss and accuracy of\n",
    "    the training and validation set.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1,2, figsize=(12,6))\n",
    "    axs[0].plot(history.history['accuracy'], label='training set')\n",
    "    axs[0].plot(history.history['val_accuracy'], label = 'validation set')\n",
    "    axs[0].set(xlabel = 'Epoch', ylabel='Accuracy', ylim=[0, 1])\n",
    "\n",
    "    axs[1].plot(history.history['loss'], label='training set')\n",
    "    axs[1].plot(history.history['val_loss'], label = 'validation set')\n",
    "    axs[1].set(xlabel = 'Epoch', ylabel='Loss', ylim=[0, 10])\n",
    "    \n",
    "    axs[0].legend(loc='lower right')\n",
    "    axs[1].legend(loc='lower right')\n",
    "    \n",
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
